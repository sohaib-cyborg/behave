# -*- coding: utf-8 -*-
"""twitter-data-sentiment-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KAR8I2HaL7FRVAIRcmhfsSGYwk6I-R4I
"""

import tweepy
import pandas as pd
from transformers import pipeline
import os
from datetime import datetime, timedelta
import numpy as np

# 1. Generate query variants for any given coin
def generate_coin_queries(coin_name: str, ticker: str):
    """
    Generates a list of query variants for a given cryptocurrency coin.
    This includes the ticker, name, and common crypto slang terms.
    """
    variants = {
        ticker,
        # f"${ticker}", # Using $ with recent tweets is often problematic
        coin_name, coin_name.lower(), coin_name.upper(),
        f"#{coin_name}", f"#{ticker}",
        # f"${ticker}USD",
        f"#{coin_name}Price"
    }
    # Simple misspelling strategy: drop one character
    for i in range(len(coin_name)):
        missp = coin_name[:i] + coin_name[i+1:]
        variants.add(missp.lower())
    # Leetspeak example
    leet = coin_name.replace('O', '0').replace('I', '1').replace('E', '3')
    variants.add(leet)
    # Crypto slang terms
    variants.update({"HODL", "FOMO", "DYOR", "WAGMI", "moon", "rugpull", "rekt"})
    return list(variants)

# 2. Initialize Tweepy client
# NOTE: The bearer_token must be set in your Colab user data or environment.
# bearer_token = userdata.get('BEARER_TOKEN')
# For this example, let's assume a token is available.
# Replace with your actual token
bearer_token = os.environ.get('BEARER_TOKEN') or "YOUR_BEARER_TOKEN_HERE"
client = tweepy.Client(bearer_token=bearer_token)

# 3. Initialize sentiment analyzer using FinTwitBERT-sentiment
sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model="StephanAkkerman/FinTwitBERT-sentiment"
)  # Specialized for financial tweets

def fetch_tweets_in_range(coin_name: str, ticker: str, max_tweets: int, start_date: datetime, end_date: datetime):
    """
    Helper function to fetch tweets within a specified date range using search_recent_tweets.
    It works by iteratively calling search_recent_tweets and moving the end date back
    until the start date is reached. This is a workaround for the 7-day lookback limit.
    """
    query = " OR ".join(generate_coin_queries(coin_name, ticker))
    query += " -is:retweet lang:en"

    all_tweets = []
    current_end_time = end_date

    while current_end_time > start_date and len(all_tweets) < max_tweets:
        print(f"Fetching tweets up to {current_end_time.isoformat()}...")
        # search_recent_tweets only supports fetching up to 100 tweets per call.
        # It also has a 7-day lookback window. This function simulates a longer history search.
        response = client.search_recent_tweets(
            query=query,
            max_results=min(max_tweets - len(all_tweets), 100),
            end_time=current_end_time,
            tweet_fields=["created_at"]
        )

        tweets = response.data or []
        all_tweets.extend(tweets)

        if not tweets:
            print("No more tweets found in this time range. Stopping.")
            break

        # Find the oldest tweet's timestamp to set the next search's end time
        oldest_tweet_time = min(tweet.created_at for tweet in tweets)
        current_end_time = oldest_tweet_time - timedelta(seconds=1)

        print(f"Fetched {len(tweets)} tweets. Total tweets so far: {len(all_tweets)}.")

    return all_tweets

def fetch_tweets(coin_name: str, ticker: str, max_tweets: int, start_date: str = None, end_date: str = None, use_all_tweets: bool = False):
    """
    Wrapper function to fetch tweets using either search_recent_tweets or search_all_tweets.
    
    Args:
        coin_name (str): The full name of the cryptocurrency.
        ticker (str): The ticker symbol of the cryptocurrency.
        max_tweets (int): The maximum number of tweets to fetch.
        start_date (str, optional): The start date in ISO format. Required for search_all_tweets.
        end_date (str, optional): The end date in ISO format.
        use_all_tweets (bool, optional): If True, uses the search_all_tweets method.
                                        This requires a higher API access level. Defaults to False.

    Returns:
        list: A list of tweepy.Tweet objects.
    """
    query = " OR ".join(generate_coin_queries(coin_name, ticker))
    query += " -is:retweet lang:en"

    # Convert date strings to datetime objects if provided
    start_dt = datetime.fromisoformat(start_date) if start_date else None
    end_dt = datetime.fromisoformat(end_date) if end_date else None

    # Logic for `search_all_tweets`
    if use_all_tweets:
        if not start_dt or not end_dt:
            raise ValueError("search_all_tweets requires both start_date and end_date.")
        print("Using search_all_tweets for historical data...")
        # Note: search_all_tweets requires a higher API access level (e.g., Academic Research or Enterprise)
        response = client.search_all_tweets(
            query=query,
            start_time=start_dt,
            end_time=end_dt,
            max_results=min(max_tweets, 500), # search_all_tweets max_results is 500
            tweet_fields=["created_at"]
        )
        return response.data or []

    # Logic for `search_recent_tweets` (default)
    else:
        if start_dt and end_dt:
            # Use the iterative helper function for a date range with the recent search endpoint
            print("Using iterative search_recent_tweets for historical data.")
            return fetch_tweets_in_range(coin_name, ticker, max_tweets, start_dt, end_dt)
        elif end_dt:
            # Use a single recent search up to the provided end date
            print("Using a single search_recent_tweets up to a specified end date.")
            response = client.search_recent_tweets(
                query=query,
                max_results=max_tweets,
                end_time=end_dt,
                tweet_fields=["created_at"]
            )
            return response.data or []
        else:
            # Default behavior: fetch recent tweets without a specific date range
            print("Using default search_recent_tweets for the last 7 days.")
            response = client.search_recent_tweets(query=query, max_results=max_tweets)
            return response.data or []

def fetch_and_analyze(coin_name: str, ticker: str, max_tweets: int = 100, start_date: str = None, end_date: str = None, use_all_tweets: bool = False):
    """
    Fetches tweets, performs sentiment analysis, and returns a DataFrame.
    This function now uses the fetch_tweets wrapper to handle different search methods.
    """
    tweets = fetch_tweets(coin_name=coin_name, ticker=ticker, max_tweets=max_tweets,
                          start_date=start_date, end_date=end_date, use_all_tweets=use_all_tweets)

    if not tweets:
        print("No tweets found.")
        return pd.DataFrame(columns=["text", "label", "score"])

    texts = [tweet.text for tweet in tweets]
    results = sentiment_analyzer(texts)
    data = []
    for tweet, res in zip(tweets, results):
        data.append({
            "text": tweet.text,
            "label": res["label"],
            "score": res["score"],
            "created_at": tweet.created_at # Adding created_at for context
        })
    return pd.DataFrame(data)

def aggregate_sentiment(df: pd.DataFrame):
    """
    Aggregates the sentiment scores from a DataFrame of analyzed tweets.
    Returns a dictionary with the overall sentiment and confidence score.
    """
    if df.empty:
        return {"overall_sentiment": "NEUTRAL", "overall_confidence": 0.0}

    label_map = {"BULLISH": 1, "NEUTRAL": 0, "BEARISH": -1}
    df['numeric_label'] = df['label'].map(label_map)

    df['weighted_score'] = df['numeric_label'] * df['score']

    total_weighted_score = df['weighted_score'].sum()
    total_confidence = df['score'].sum()

    if total_confidence == 0:
        return {"overall_sentiment": "NEUTRAL", "overall_confidence": 0.0}

    aggregated_score = total_weighted_score / total_confidence

    # Define thresholds for sentiment classification
    if aggregated_score > 0.1:
        overall_sentiment = "BULLISH"
    elif aggregated_score < -0.1:
        overall_sentiment = "BEARISH"
    else:
        overall_sentiment = "NEUTRAL"

    overall_confidence = abs(aggregated_score)

    return {
        "overall_sentiment": overall_sentiment,
        "overall_confidence": overall_confidence
    }

# Example usage
if __name__ == "__main__":
    # Example 1: Fetching recent tweets using the default method
    print("--- Example 1: Fetching recent tweets using the default method ---")
    df_recent = fetch_and_analyze("Ethereum", "ETH", max_tweets=50)
    print("Per-tweet sentiment analysis:")
    if not df_recent.empty:
        print(df_recent.head())
        aggregated_result_recent = aggregate_sentiment(df_recent)
        print("\nOverall aggregated sentiment:")
        print(f"Sentiment: {aggregated_result_recent['overall_sentiment']}")
        print(f"Confidence: {aggregated_result_recent['overall_confidence']:.4f}")
    else:
        print("No tweets found for this example.")

    print("\n" + "="*50 + "\n")

    # Example 2: Fetching tweets over a historical date range using the default method
    print("--- Example 2: Fetching tweets over a historical date range using the default method ---")
    # This will use the iterative helper function
    start = (datetime.now() - timedelta(days=3)).isoformat()
    end = datetime.now().isoformat()
    df_range = fetch_and_analyze("Bitcoin", "BTC", max_tweets=150, start_date=start, end_date=end)
    print("Per-tweet sentiment analysis:")
    if not df_range.empty:
        print(df_range.head())
        aggregated_result_range = aggregate_sentiment(df_range)
        print("\nOverall aggregated sentiment:")
        print(f"Sentiment: {aggregated_result_range['overall_sentiment']}")
        print(f"Confidence: {aggregated_result_range['overall_confidence']:.4f}")
    else:
        print("No tweets found for this date range.")

    print("\n" + "="*50 + "\n")

    # Example 3: Fetching historical tweets using the search_all_tweets method
    # NOTE: This requires a higher API access tier, so it may not work with
    # a standard developer account.
    print("--- Example 3: Fetching historical tweets using search_all_tweets ---")
    # Using a hypothetical historical range
    start_historical = (datetime.now() - timedelta(days=10)).isoformat()
    end_historical = (datetime.now() - timedelta(days=8)).isoformat()
    try:
        df_all = fetch_and_analyze("Dogecoin", "DOGE", max_tweets=200, start_date=start_historical, end_date=end_historical, use_all_tweets=True)
        print("Per-tweet sentiment analysis:")
        if not df_all.empty:
            print(df_all.head())
            aggregated_result_all = aggregate_sentiment(df_all)
            print("\nOverall aggregated sentiment:")
            print(f"Sentiment: {aggregated_result_all['overall_sentiment']}")
            print(f"Confidence: {aggregated_result_all['overall_confidence']:.4f}")
        else:
            print("No tweets found for this historical range.")
    except Exception as e:
        print(f"Could not use search_all_tweets. Please ensure you have the correct API access level. Error: {e}")
